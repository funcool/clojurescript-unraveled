=== Transducers

==== Data transformation

ClojureScript offers a rich vocabulary for data transformation in terms of the sequence abstraction,
which makes such transformations highly general and composable. Let's see how we can combine several
collection processing functions to build new ones. We will be using a simple problem throughout this
section: splitting grape clusters, filtering out the rotten ones, and cleaning them. We have a collection
of grape clusters like the following:

[source, clojure]
----
(def grape-clusters [{:grapes [{:rotten? false :clean? false}
                               {:rotten? true :clean? false}]
                      :color :green}
                     {:grapes [{:rotten? true :clean? false}
                               {:rotten? false :clean? false}]
                      :color :black}])
----

We are interested in splitting the grape clusters into individual grapes, discarding the rotten ones
and cleaning the remaining grapes so they are ready for eating. We are well-equipped in ClojureScript
for this data transformation task; we could implement it using the familiar `map`, `filter` and `mapcat`
functions:

[source, clojure]
----
(defn split-cluster
  [c]
  (:grapes c))

(defn not-rotten
  [g]
  (not (:rotten? g)))

(defn clean-grape
  [g]
  (assoc g :clean? true))

(->> grape-clusters
     (mapcat split-cluster)
     (filter not-rotten)
     (map clean-grape))
;; => ({rotten? false :clean? true} {:rotten? false :clean? true})
----

In the above example we succintly solved the problem of selecting and cleaning the grapes, and
we can even abstract such transformations by combining the `mapcat`, `filter` and `map` operations
using partial application and function composition:

[source, clojure]
----
(def process-clusters
  (comp
    (partial map clean-grape)
    (partial filter not-rotten)
    (partial mapcat split-cluster)))

(process-clusters grape-clusters)
;; => ({rotten? false :clean? true} {:rotten? false :clean? true})
----

The code is very clean, but it has a few problems. For example, each call to `map`, `filter` and
`mapcat` consumes and produces a sequence that, although lazy, generates intermediate results
that will be discarded. Each sequence is fed to the next step, which also returns a
sequence. Wouldn't be great if we could do the transformation in a single transversal of the `grape-cluster`
collection?

Another problem is that even though our `process-clusters` function works with any sequence, we
can't reuse it with anything that is not a sequence. Imagine that instead of having the grape cluster
collection available in memory it is being pushed to us asynchronously in a stream. In that situation
we couldn't reuse `process-clusters` since usually `map`, `filter` and `mapcat` have concrete
implementations depending on the type.

==== Generalizing to process transformations

The process of mapping, filtering or mapcatting isn't necesarily tied to a concrete type, but we
keep reimplementing them for different types. Let's see how we can generalize such processes to
be context independent. We'll start by implementing naive versions of `map` and `filter` first to
see how they work internally:

[source, clojure]
----
(defn my-map
  [f coll]
  (when-let [s (seq coll)]
    (cons (f (first s)) (my-map f (rest s)))))

(my-map inc [0 1 2])
;; => (1 2 3)

(defn my-filter
  [pred coll]
  (when-let [s (seq coll)]
    (let [f (first s)
          r (rest s)]
      (if (pred f)
        (cons f (my-filter pred r))
        (my-filter pred r)))))

(my-filter odd? [0 1 2])
;; => (1)
----

As we can see, they both assume that they receive a seqable and return a sequence. Like many recursive
functions they can be implemented in terms of the already familiar `reduce` function. Note that functions
that are given to reduce receive an accumulator and an input and return the next accumulator. We'll call
these types of functions reducing functions from now on.

[source, clojure]
----
(defn my-mapr
  [f coll]
  (reduce (fn [acc input]         ;; reducing function
            (conj acc (f input)))
          []                      ;; initial value
          coll))                  ;; collection to reduce

(my-mapr inc [0 1 2])
;; => [1 2 3]

(defn my-filterr
  [pred coll]
  (reduce (fn [acc input]         ;; reducing function
            (if (pred input)
              (conj acc input)
              acc))
          []                      ;; initial value
          coll))                  ;; collection to reduce

(my-filterr odd? [0 1 2])
;; => [1]
----

We've made the previous versions more general since using `reduce` makes our functions work on any thing
that is reducible, not just sequences. However you may have noticed that, even though `my-mapr` and `my-filterr`
don't know anything about the source (`coll`) they are still tied to the output they produce (a vector) both
with the initial value of the reduce (`[]`) and the hardcoded `conj` operation in the body of the reducing
function. We could have accumulated results in another data structure, for example a lazy sequence, but
we'd have to rewrite the functions in order to do so.

How can we make these functions truly generic? They shouldn't know about either the source of inputs they
are transforming nor the output that is generated. Have you noticed that `conj` is just another reducing
function? It takes an accumulator and an input and returns another accumulator. So, if we parameterise
the reducing function that `my-mapr` and `my-filterr` use, they won't know anything about the type of the
result they are building. Let's give it a shot:

[source, clojure]
----
(defn my-mapt
  [f]                         ;; function to map over inputs
  (fn [rfn]                   ;; parameterised reducing function
    (fn [acc input]           ;; transformed reducing function, now it maps `f`!
      (rfn acc (f input)))))

(def incer (my-mapt inc))

(reduce (incer conj) [] [0 1 2])
;; => [1 2 3]

(defn my-filtert
  [pred]                      ;; predicate to filter out inputs
  (fn [rfn]                   ;; parameterised reducing function
    (fn [acc input]           ;; transformed reducing function, now it discards values based on `pred`!
      (if (pred input)
        (rfn acc input)
        acc))))

(def only-odds (my-filtert odd?))

(reduce (only-odds conj) [] [0 1 2])
;; => [1]
----

That's a lot of higher-order functions so let's break it down for a better understanding of what's going
on. We'll examine how `my-mapt` works step by step. The mechanics are similar for `my-filtert`, so we'll
leave it out for now.

First of all, `my-mapt` takes a mapping function; in the example we are giving it `inc` and getting
another function back. Let's replace `f` with `inc` to see what we are building:

[source, clojure]
----
(def incer (my-mapt inc))
;; (fn [rfn]
;;   (fn [acc input]
;;     (rfn acc (inc input))))
;;               ^^^
----

The resulting function is still parameterised to receive a reducing function to which it will delegate,
let's see what happens when we call it with `conj`:

[source, clojure]
----
(incer conj)
;; (fn [acc input]
;;   (conj acc (inc input)))
;;    ^^^^
----

We get back a reducing function which uses `inc` to transform the inputs and the `conj` reducing function
to accumulate the results. In essence, we have defined map as the transformation of a reducing function.
The functions that transform one reducing function into another are called transducers in ClojureScript.

To ilustrate the generality of transducers, let's use different sources and destinations in our call
to `reduce`:

[source, clojure]
----
(reduce (incer str) "" [0 1 2])
;; => "123"

(reduce (only-odds str) "" '(0 1 2))
;; => "1"
----

The transducer versions of `map` and `filter` transform a process that carries inputs from a source to a
destination but don't know anything about where the inputs come from and where they end up. In their
implementation they contain the _essence_ of what they accomplish, independent of context.

Now that we know more about transducers we can try to implement our own version of `mapcat`. We already have
a fundamental piece of it: the `map` transducer. What `mapcat` does is map a function over an input and flatten
the resulting structure one level. Let's try to implement the catenation part as a transducer:

[source, clojure]
----
(defn my-cat
  [rfn]
  (fn [acc input]
    (reduce rfn acc input)))

(reduce (my-cat conj) [] [[0 1 2] [3 4 5]])
;; => [0 1 2 3 4 5]
----

The `my-cat` transducer returns a reducing function that catenates its inputs into the accumulator. It does so
reducing the `input` reducible with the `rfn` reducing function and using the accumulator (`acc`) as the
initial value for such reduction. `mapcat` is simply the composition of `map` and `cat`. The order in which
transducers are composed may seem backwards but it'll become clear in a moment.

[source, clojure]
----
(defn my-mapcat
  [f]
  (comp (my-mapt f) my-cat))

(defn dupe
  [x]
  [x x])

(def duper (my-mapcat dupe))

(reduce (duper conj) [] [0 1 2])
;; => [0 0 1 1 2 2]
----

==== Transducers in ClojureScript core

Some of the ClojureScript core functions like `map`, `filter` and `mapcat` support an arity 1 version
that returns a transducer. Let's revisit our definition of `process-cluster` and define it in terms of
transducers:

[source, clojure]
----
(def process-clusters
  (comp
    (mapcat split-cluster)
    (filter not-rotten)
    (map clean-grape)))
----

A few things changed since our previous definition `process-clusters`. First of all, we are using the
transducer-returning versions of `mapcat`, `filter` and `map` instead of partially applying them for
working on sequences.

Also you may have noticed that the order in which they are composed is reversed, they appear in the order
they are executed. Note that all `map`, `filter` and `mapcat` return a transducer. `filter` transforms the
reducing function returned by `map`, applying the filtering before proceeding; `mapcat` transforms the reducing
function returned by `filter`, applying the mapping and catenation before proceeding.

One of the powerful properties of transducers is that they are combined using regular function composition.
What's even more elegant is that the composition of various transducers is itself a transducer! This means
that our `process-cluster` is a transducer too, so we have defined a composable and context-independent
algorithmic transformation.

Many of the core ClojureScript functions accept a transducer, let's look at some examples with our newly
created `process-cluster`:

[source, clojure]
----
(into [] process-clusters grape-clusters)
;; => [{:rotten? false, :clean? true} {:rotten? false, :clean? true}]

(sequence process-clusters grape-clusters)
;; => ({:rotten? false, :clean? true} {:rotten? false, :clean? true})

(reduce (process-clusters conj) [] grape-clusters)
;; => [{:rotten? false, :clean? true} {:rotten? false, :clean? true}]
----

Since using `reduce` with the reducing function returned from a transducer is so common, there is
a function for reducing with a transformation called `transduce`. We can now rewrite the previous call
to `reduce` using `transduce`:

[source, clojure]
----
(transduce process-clusters conj [] grape-clusters)
;; => [{:rotten? false, :clean? true} {:rotten? false, :clean? true}]
----

==== Initialisation

In the last example we provided an initial value to the `transduce` function (`[]`) but we can omit it
and get the same result:

[source, clojure]
----
(transduce process-clusters conj grape-clusters)
;; => [{:rotten? false, :clean? true} {:rotten? false, :clean? true}]
----

What's going on here? How can `transduce` know what initial value use as an accumulator when we haven't
specified it? Try calling `conj` without any arguments and see what happens:

[source, clojure]
----
(conj)
;; => []
----

The `conj` function has a arity 0 version that returns an empty vector but is not the only reducing function
that supports arity 0. Let's explore some others:

[source, clojure]
----
(+)
;; => 0

(*)
;; => 1

(str)
;; => ""

(= identity (comp))
;; => true
----

The reducing function returned by transducers must support the arity 0 as well, which will typically delegate
to the transformed reducing function. There is no sensible implementation of the arity 0 for the transducers
we have implemented so far, so we'll simply call the reducing function without arguments. Here's how our
modified `my-mapt` could look like:

[source, clojure]
----
(defn my-mapt
  [f]
  (fn [rfn]
    (fn
      ([] (rfn))                ;; arity 0 that delegates to the reducing fn
      ([acc input]
        (rfn acc (f input))))))
----

The call to the arity 0 of the reducing function returned by a transducer will call the arity 0 version of
every nested reducing function, eventually calling the outermost reducing function. Let's see an example with
our already defined `process-clusters` transducer:

[source, clojure]
----
((process-clusters conj))
;; => []
----

The call to the arity 0 flows through the transducer stack, eventually calling `(conj)`.

==== Stateful transducers

So far we've only seen purely functional transducer; they don't have any implicit state and are very
predictable. However, there are many data transformation functions that are inherently stateful, like
`take`. `take` receives a number `n` of elements to keep and a collection and returns a collection with at
most `n` elements.

[source, clojure]
----
(take 10 (range 100))
;; => (0 1 2 3 4 5 6 7 8 9)
----

Let's step back for a bit and learn about the early termination of the `reduce` function. We can wrap an
accumulator in a type called `reduced` for telling `reduce` that the reduction process should terminate
immediately. Let's see an example of a reduction that aggregates the inputs in a collection and finishes
as soon as there are 10 elements in the accumulator:

[source, clojure]
----
(reduce (fn [acc input]
          (if (= (count acc) 10)
            (reduced acc)
            (conj acc input)))
         []
         (range 100))
;; => [0 1 2 3 4 5 6 7 8 9]
----

Since transducers are modifications of reducing functions they also use `reduced` for early termination.
Note that stateful transducers may need to do some cleanup before the process terminates, so they
must support an arity 1 as a "completion" step. Usually, like with arity 0, this arity will simply delegate
to the transformed reducing function's arity 1.

Knowing this we are able to write stateful transducers like `take`. We'll be using mutable state internally
for tracking the number of inputs we have seen so far, and wrap the accumulator in a `reduced` as soon as
we've seen enough elements:

[source, clojure]
----
(defn my-take
  [n]
  (fn [rfn]
    (let [remaining (volatile! n)]
      (fn
        ([] (rfn))
        ([acc] (rfn acc))
        ([acc input]
          (let [rem @remaining
                nr (vswap! remaining dec)
                result (if (pos? rem)
                         (rfn acc input)   ;; we still have items to take
                         acc)]             ;; we're done, acc becomes the result
            (if (not (pos? nr))
              (ensure-reduced result)      ;; wrap result in reduced if not already
              result)))))))
----

This is a simplified version of the `take` function present in ClojureScript core. There are
a few things to note here so let's break it up in pieces to understand it better.

The first thing to notice is that we are creating a mutable value inside the transducer. Note
that we don't create it until we receive a reducing function to transform. If we created it before
returning the transducer we couldn't use `my-take` more than once. Since the transducer is handed
a reducing function to transform each time it is used, we can use it multiple times and the mutable
variable will be created in every use.

[source, clojure]
----
(fn [rfn]
  (let [remaining (volatile! n)] ;; make sure to create mutable variables inside the transducer
    (fn
      ;; ...
)))

(def take-five (my-take 5))

(transduce take-five conj (range 100))
;; => [0 1 2 3 4]

(transduce take-five conj (range 100))
;; => [0 1 2 3 4]
----

Let's now dig into the reducing function returned from `my-take`. First of all we `deref` the volatile
to get the number of elements that remain to be taken and decrement it to get the next remaining value.
If there are still remaining items to take, we call `rfn` passing the accumulator and input; if not, we
already have the final result.

[source, clojure]
----
([acc input]
  (let [rem @remaining
        nr (vswap! remaining dec)
        result (if (pos? rem)
                 (rfn acc input)
                 acc)]
    ;; ...
))
----

The body of `my-take` should be obvious by now. We check whether there are still items to be processed
using the next remainder (`nr`) and, if not, wrap the result in a `reduced` using the `ensure-reduced`
function. `ensure-reduced` will wrap the value in a `reduced` if it's not reduced already or simply return
the value if it's already reduced. In case we are not done yet, we return the accumulated `result` for
further processing.

[source, clojure]
----
(if (not (pos? nr))
  (ensure-reduced result)
  result)
----

We've seen an example of a stateful transducer but it didn't do anything in its completion step. Let's
see an example of a transducer that uses the completion step to flush an accumulated value. We'll
implement a simplified version of `partition-all`, which given a `n` number of elements converts the inputs
in vectors of size `n`. For understanding its purpose better let's see what the arity 2 version gives us when
providing a number and a collection:

[source, clojure]
----
(partition-all 3 (range 10))
;; => ((0 1 2) (3 4 5) (6 7 8) (9))
----

The transducer returning function of `partition-all` will take a number `n` and return a transducer that groups
inputs in vectors of size `n`. In the completion step it will check if there is an accumulated result and, if so,
add it to the result. Here's a simplified version of ClojureScript core `partition-all` function, where `array-list`
is a wrapper for a mutable JavaScript array:

[source, clojure]
----
(defn my-partition-all
  [n]
  (fn [rfn]
    (let [a (array-list)]
      (fn
        ([] (rfn))
        ([result]
          (let [result (if (.isEmpty a)                  ;; no inputs accumulated, don't have to modify result
                         result
                         (let [v (vec (.toArray a))]
                           (.clear a)                    ;; flush array contents for garbage collection
                           (unreduced (rfn result v))))] ;; pass to `rfn`, removing the reduced wrapper if present
            (rfn result)))
        ([acc input]
          (.add a input)
          (if (== n (.size a))                           ;; got enough results for a chunk
            (let [v (vec (.toArray a))]
              (.clear a)
              (rfn acc v))                               ;; the accumulated chunk becomes input to `rfn`
            acc))))))

(def triples (my-partition-all 3))

(transduce triples conj (range 10))
;; => [[0 1 2] [3 4 5] [6 7 8] [9]]
----

==== Eductions

Eductions are a way to combine a collection and one or more transformations that can be reduced and iterated over,
and that apply the transformations every time we do so. If we have a collection that we want to process and a
transformation over it that we want others to extend, we can hand them a eduction, encapsulating the source
collection and our transformation. We can create an eduction with the `eduction` function:

[source, clojure]
----
(def ed (eduction (filter odd?) (take 5) (range 100)))

(reduce + 0 ed)
;; => 25

(transduce (partition-all 2) conj ed)
;; => [[1 3] [5 7] [9]]
----

==== More transducers in ClojureScript core

We learned about `map`, `filter`, `mapcat`, `take` and `partition-all`, but there are a lot more transducers
available in ClojureScript. Here is an incomplete list of some other intersting ones:

- `drop` is the dual of `take`, dropping up to `n` values before passing inputs to the reducing function
- `distinct` only allows inputs to occur once
- `dedupe` removes succesive duplicates in input values

We encourage you to explore ClojureScript core to see what other transducers are out there.

==== Defining our own transducers

Since most transducers are only interesting in the reducing step implementation and often delegate to the
reducing function in arities 0 and 1, there is a little helper called `completing` that fills those arities
for you:
////
I think this needs a bit more explanation. Why does my-transducer use completing also, and how is it different from my-transducer-with-completion?
////

[source, clojure]
----
;; if a completing function is not defined, identity will be used
(def my-transducer
  (completing
    (fn [acc input]
     ;; ...
     )))

(def my-transducer-with-completion
  (completing
    (fn [acc input]
     ;; ...
     )
    (fn [result]
     ;; ...
    )))
----


==== Transducible processes

A transducible process is any process that is defined in terms of a succession of steps ingesting input values.
The source of input varies from one process to another. Most of our examples dealt with inputs from a collection
or a lazy sequence, but it could be an asynchronous stream of values or a `core.async` channel. The outputs produced
by each step are also different for every process; `into` creates a collection with every output of the transducer,
`sequence` yields a lazy sequence, and asynchronous streams would probably push the outputs to their listeners.

In order to improve our understanding of transducible processes, we're going to implement an unbounded queue, since adding
values to a queue can be thought in terms of a succession of steps ingesting input. First of all we'll define a
protocol and a data type that implements the unbounded queue:

[source, clojure]
----
(defprotocol Queue
  (put! [q item] "put an item into the queue")
  (take! [q] "take an item from the queue")
  (shutdown! [q] "stop accepting puts in the queue"))

(deftype UnboundedQueue [^:mutable arr ^:mutable closed]
  Queue
  (put! [_ item]
    (assert (not closed))
    (assert (not (nil? item)))
    (.push arr item)
    item)
  (take! [_]
    (aget (.splice arr 0 1) 0))
  (shutdown! [_]
    (set! closed true)))
----

We defined the `Queue` protocol and as you may have noticed the implementation of `UnboundedQueue` doesn't
know about transducers at all. It has a `put!` operation as its step function and we're going to implement
the transducible process on top of that interface:

[source, clojure]
----
(defn unbounded-queue
  ([]
   (queue nil))
  ([xform]
   (let [put! (completing put!)
         xput! (if xform (xform put!) put!)
         q (UnboundedQueue. #js [] false)]
     (reify
       Queue
       (put! [_ item]
         (when-not (.-closed q)
           (let [val (xput! q item)]
             (if (reduced? val)
               (do
                 (xput! @val)  ;; call completion step
                 (shutdown! q) ;; respect reduced
                 @val)
               val))))
       (take! [_]
         (take! q))
       (shutdown! [_]
         (shutdown! q))))))
----

As you can see, the `unbounded-queue` constructor uses an `UnboundedQueue` instance internally, proxying the
`take!` and `shutdown!` calls and implementing the transducible process logic in the `put!` function. Let's
deconstruct it to understand what's going on.

[source, clojure]
----
(let [put! (completing put!)
      xput! (if xform (xform put!) put!)
      q (UnboundedQueue. #js [] false)]
  ;; ...
)
----

First of all, we use `completing` for adding the arity 0 and arity 1 to the `Queue` protocol's `put!` function.
This will make it play nicely with transducers in case we give this reducing function to `xform` to derive another.
After that, if a transducer (`xform`) was provided, we derive a reducing function applying the transducer to `put!`.
If we're not handed a transducer we will just use `put!`. `q` is the internal instance of `UnboundedQueue`.

[source, clojure]
----
(reify
  Queue
  (put! [_ item]
    (when-not (.-closed q)
      (let [val (xput! q item)]
        (if (reduced? val)
          (do
            (xput! @val)  ;; call completion step
            (shutdown! q) ;; respect reduced
            @val)
          val))))
  ;; ...
)
----

The exposed `put!` operation will only be performed if the queue hasn't been shut down. Notice that the `put!`
implementation of `UnboundedQueue` uses an assert to verify that we can still put values to it and we don't
want to break that invariant. If the queue isn't closed we can put values into it, we use the possibly transformed
`xput!` for doing so.

If the put operation gives back a reduced value it's telling us that we should terminate the transducible process.
In this case that means shutting down the queue to not accept more values. If we didn't get a reduced value we can
happily continue accepting puts.

Let's see how our queue behaves without transducers:

[source, clojure]
----
(def q (queue))
;; => #<[object Object]>

(put! q 1)
;; => 1
(put! q 2)
;; => 2

(take! q)
;; => 1
(take! q)
;; => 2
(take! q)
;; => nil
----

Pretty much what we expected, let's now try with a stateless transducer:

[source, clojure]
----
(def incq (queue (map inc)))
;; => #<[object Object]>

(put! incq 1)
;; => 2
(put! incq 2)
;; => 3

(take! incq)
;; => 2
(take! incq)
;; => 3
(take! incq)
;; => nil
----

To check that we've implemented the transducible process, let's use a stateful transducer. We'll use a transducer
that will accept values while they aren't equal to 4 and will partition inputs in chunks of 2 elements:

[source, clojure]
----
(def xq (queue (comp
                 (take-while #(not= % 4))
                 (partition-all 2))))

(put! xq 1)
(put! xq 2)
;; => [1 2]
(put! xq 3)
(put! xq 4) ;; shouldn't accept more values from here on
(put! xq 5)
;; => nil

(take! xq)
;; => [1 2]
(take! xq) ;; seems like `partition-all` flushed correctly!
;; => [3]
(take! xq)
;; => nil
----

The example of the queue was heavily inspired by how `core.async` channels use transducers in their internal
step. We'll discuss channels and their usage with transducers in a later section.

Transducible processes must respect `reduced` as a way for signaling early termination. For example,
building a collection stops when encountering a `reduced` and `core.async` channels with transducers are closed.
The `reduced` value must be unwrapped with `deref` and passed to the completion step, which must be called exactly
once.

Transducible processes shouldn't expose the reducing function they generate when calling the transducer with their
own step function since it may be stateful and unsafe to use from elsewhere.


=== Transients

Although ClojureScript's immutable and persistent data structures are reasonably performant
there are situations in which we are transforming large data structures using multiple steps
to only share the final result. For example, the core `into` function takes a collection and eagerly
populates it with the contents of a sequence:

[source, clojure]
----
(into [] (range 100))
;; => [0 1 2 ... 98 99]
----

In the above example we are generating a vector of 100 elements `conj`-ing one at a time. Every
intermediate vector that is not the final result won't be seen by anybody except the `into`
function and the array copying required for persistence is an unnecesary overhead.

For these situations ClojureScript provides a special version of some of its persistent data
structures, which are called transients. Maps, vectors and sets have a transient counterpart.
Transients are always derived from a persistent data structure using the `transient` function,
which creates a transient version in constant time:

[source, clojure]
----
(def tv (transient [1 2 3]))
;; => #<[object Object]>
----

Transients support the read API of their persistent counterparts:

[source, clojure]
----
(def tv (transient [1 2 3]))

(nth tv 0)
;; => 1

(get tv 2)
;; => 3

(def tm (transient {:language "ClojureScript"}))

(:language tm)
;; => "ClojureScript"

(def ts (transient #{:a :b :c}))

(contains? ts :a)
;; => true

(:a ts)
;; => :a
----

Since transients don't have persistent and immutable semantics for updates they can't be transformed
using the already familiar `conj` or `assoc` functions. Instead, the transforming functions that work
on transients end with a bang. Let's look at an example using `conj!` on a transient:

[source, clojure]
----
(def tv (transient [1 2 3]))

(conj! tv 4)
;; => #<[object Object]>

(nth tv 3)
;; => 4
----

As you can see, the transient version of the vector is neither immutable or persistent. Instead, the
vector is mutated in place. Although we could transform `tv` repeatedly using `conj!` on it we shouldn't
abandon the idioms used with the persistent data structures: when transforming a transient, use the
returned version of it for further modifications like in the following example:

[source, clojure]
----
(-> [1 2 3]
  transient
  (conj! 4)
  (conj! 5))
;; => #<[object Object]>
----

We can convert a transient back to a persistent and immutable data structure by calling `persistent!` on
it. This operation, like deriving a transient from a persistent data structure, is done in constant time.

[source, clojure]
----
(-> [1 2 3]
  transient
  (conj! 4)
  (conj! 5)
  persistent!)
;; => [1 2 3 4 5]
----

A peculiarity of transforming transients into persistent structures is that the transient version is
invalidated after being converted to a persistent data structure and we can't do further transformations
to it. This happens because the derived persistent data structure uses the transient's internal nodes
and mutating them would break the immutability and persistent guarantees:

[source, clojure]
----
(def tm (transient {}))
;; => #<[object Object]>

(assoc! tm :foo :bar)
;; => #<[object Object]>

(persistent! tm)
;; => {:foo :bar}

(assoc! tm :baz :frob)
;; Error: assoc! after persistent!
----

Going back to our initial example with `into`, here's a very simplified implementation of it that uses
a transient for performance, returning a persistent data structure and thus exposing a purely functional
interface although it uses mutation internally:

[source, clojure]
----
(defn my-into
  [to from]
  (persistent! (reduce conj! (transient to) from)))

(my-into [] (range 100))
;; => [0 1 2 ... 98 99]
----


=== Metadata

ClojureScript symbols, vars and persistent collections support attaching metadata to them. Metadata is
a map with information about the entity it's attached to. The ClojureScript compiler uses metadata for
several purposes such as type hints, and the metadata system can be used by tooling, library and application
developers too.

There may not be many cases in day-to-day ClojureScript programming where you need metadata, but it is a
nice language feature to have and know about; it may come in handy at some point. It makes things like
runtime code introspection and documentation generation very easy. You'll see why throughout this section.

==== Vars

Let's define a var and see what metadata is attached to it by default. Note that this code is executed in
a REPL, and thus the metadata of a var defined in a source file may vary. We'll use the `meta` function to
retrieve the metadata of the given value:

[source, clojure]
----
(def answer-to-everything 42)
;; => 42

#'answer-to-everything
;; => #'cljs.user/answer-to-everyhing

(meta #'answer-to-everything)
;; => {:ns cljs.user,
;;     :name answer-to-everything,
;;     :file "NO_SOURCE_FILE",
;;     :source "answer-to-everything",
;;     :column 6,
;;     :end-column 26,
;;     :line 1,
;;     :end-line 1,
;;     :arglists (),
;;     :doc nil,
;;     :test nil}
----

Few things to note here. First of all, `#'answer-to-everything` gives us a reference to the `Var` that holds
the value of the `answer-to-everything` symbol. We see that it includes information about the namespace (`:ns`) in
which it was defined, its name, file (although, since it was defined at a REPL doesn't have a source file),
source, position in the file where it was defined, argument list (which only makes sense for functions),
documentation string and test function.

Let's take a look at a function var's metadata:

[source, clojure]
----
(defn add
  "A function that adds two numbers."
  [x y]
  (+ x y))

(meta #'add)
;; => {:ns cljs.user,
;;     :name add,
;;     :file "NO_SOURCE_FILE",
;;     :source "add",
;;     :column 7,
;;     :end-column 10,
;;     :line 1,
;;     :end-line 1,
;;     :arglists (quote ([x y])),
;;     :doc "A function that adds two numbers.",
;;     :test nil}
----

We see that the argument lists are stored in the `:arglists` field of the var's metadata and its documentation
in the `:doc` field. We'll now define a test function to learn about what `:test` is used for:

[source, clojure]
----
(require '[cljs.test :as t])

(t/deftest i-pass
  (t/is true))

(meta #'i-pass)
;; => {:ns cljs.user,
;;     :name i-pass,
;;     :file "NO_SOURCE_FILE",
;;     :source "i-pass",
;;     :column 12,
;;     :end-column 18,
;;     :line 1,
;;     :end-line 1,
;;     :arglists (),
;;     :doc "A function that adds two numbers.",
;;     :test #<function (){ ... }>}
----

The `:test` attribute (truncated for brevity) in the `i-pass` var's metadata is a test function. This is used
by the `cljs.test` library for discovering and running tests in the namespaces you tell it to.

==== Values

We learned that vars can have metadata and what kind of metadata is added to them for consumption by the
compiler and the `cljs.test` testing library. Persistent collections can have metadata too, although they don't
have any by default. We can use the `with-meta` function to derive an object with the same value and type with
the given metadata attached. Let's see how:

[source, clojure]
----
(def map-without-metadata {:language "ClojureScript"})
;; => {:language "ClojureScript"}

(meta map-without-metadata)
;; => nil

(def map-with-metadata (with-meta map-without-metadata
                                  {:answer-to-everything 42}))
;; => {:language "ClojureScript"}

(meta map-with-metadata)
;; => {:answer-to-everything 42}

(= map-with-metadata
   map-without-metadata)
;; => true

(identical? map-with-metadata
            map-without-metadata)
;; => false
----

It shouldn't come as a surprise that metadata doesn't affect equality between two data structures since
equality in ClojureScript is based on value. Another interesting thing is that `with-meta` creates another
object of the same type and value as the given one and attaches the given metadata to it.

Another open question is what happens with metadata when deriving new values from a persistent data structure.
Let's find out:

[source, clojure]
----
(def derived-map (assoc map-with-metadata :language "Clojure"))
;; => {:language "Clojure"}

(meta derived-map)
;; => {:answer-to-everything 42}
----

As you can see in the example above, metadata is preserved in derived versions of persistent data structures. There
are some subtleties, though. As long as the functions that derive new data structures return collections with the
same type, metadata will be preserved; this is not true if the types change due to the transformation. To
ilustrate this point, let's see what happens when we derive a seq or a subvector from a vector:

[source, clojure]
----
(def v (with-meta [0 1 2 3] {:foo :bar}))
;; => [0 1 2 3]

(def sv (subvec v 0 2))
;; => [0 1]

(meta sv)
;; => nil

(meta (seq v))
;; => nil
----

==== Syntax for metadata

The ClojureScript reader has syntactic support for metadata annotations, which can be written in different ways. We
can prepend var definitions or collections with a caret (`^`) followed by a map for annotating it with the given
metadata map:

[source, clojure]
----
(def ^{:doc "The answer to Life, Universe and Everything."} answer-to-everything 42)
;; => 42

(meta #'answer-to-everything)
;; => {:ns cljs.user,
;;     :name answer-to-everything,
;;     :file "NO_SOURCE_FILE",
;;     :source "answer-to-everything",
;;     :column 6,
;;     :end-column 26,
;;     :line 1,
;;     :end-line 1,
;;     :arglists (),
;;     :doc "The answer to Life, Universe and Everything.",
;;     :test nil}

(def map-with-metadata ^{:answer-to-everything 42} {:language "ClojureScript"})
;; => {:language "ClojureScript"}

(meta map-with-metadata)
;; => {:answer-to-everything 42}
----

Notice how the metadata given in the `answer-to-everything` var definition is merged with the var metadata.

A very common use of metadata is to set certain keys to a `true` value. For example we may want to add to a
var's metadata that the variable is dynamic or a constant. For such cases, we have a shorthand notation that
uses a caret followed by a keyword. Here are some examples:

[source, clojure]
----
(def ^:dynamic *foo* 42)
;; => 42

(:dynamic (meta #'*foo*))
;; => true

(def ^:foo ^:bar answer 42)
;; => 42

(select-keys (meta #'answer) [:foo :bar])
;; => {:foo true, :bar true}
----

There is another shorthand notation for attaching metadata. If we use a caret followed by a symbol it will
be added to the metadata map under the `:tag` key. Using tags such as `^boolean` gives the ClojureScript
compiler hints about the type of expressions or function return types.

[source, clojure]
----
(defn ^boolean will-it-blend? [_] true)
;; => #<function ... >

(:tag (meta #'will-it-blend?))
;; => boolean

(not ^boolean (js/isNaN js/NaN))
;; => false
----

==== Functions for working with metadata

We've learned about `meta` and `with-meta` so far but ClojureScript offers a few functions for transforming
metadata. There is `vary-meta` which is similar to `with-meta` in that it derives a new object with the same
type and value as the original but it doesn't take the metadata to attach directly. Instead, it takes a function
to apply to the metadata of the given object to transform it for deriving new metadata. This is how it works:

[source, clojure]
----
(def map-with-metadata ^{:foo 40} {:language "ClojureScript"})
;; => {:language "ClojureScript"}

(meta map-with-metadata)
;; => {:foo 40}

(def derived-map (vary-meta map-with-metadata update :foo + 2))
;; => {:language "ClojureScript"}

(meta derived-map)
;; => {:foo 42}
----

If instead we want to change the metadata of an existing var or value we can use `alter-meta!` for changing it
by applying a function or `reset-meta!` for replacing it with another map:

[source, clojure]
----
(def map-with-metadata ^{:foo 40} {:language "ClojureScript"})
;; => {:language "ClojureScript"}

(meta map-with-metadata)
;; => {:foo 40}

(alter-meta! map-with-metadata update :foo + 2)
;; => {:foo 42}

(meta map-with-metadata)
;; => {:foo 42}

(reset-meta! map-with-metadata {:foo 40})
;; => {:foo 40}

(meta map-with-metadata)
;; => {:foo 40}
----


=== Macros

////
Intends to be a little explanation to macros (an extensive documentation is not a goal,
because it fits perfectly into its own book) and the peculiarities of the clojurescript
in respect to the clojure.
////

TBD


=== Core protocols

////
As clojurescript in difference with Clojure defines everything in terms of protocols and this
subchapter intends to expain many of these protocols and how them can be used by the user.
////

TBD


=== CSP & core.async

CSP stands for Communicating Sequential Processes, which is a formalism for describing
concurrent systems pioneered by C. A. R. Hoare in 1978. It is a concurrency model based
on message passing and synchronization through channels. An in-depth look at the
theoretical model behind CSP is out of the scope of this book, instead we'll focus on
presenting the concurrency primitives that `core.async` offers.

`core.async` is not part of ClojureScript core but it's implemented as a library. Even
though is not part of the core language it's widely used and many libraries build on top
of its primitives so we think is worth covering in the book. It's also a good example of
the syntactic abstractions that can be achieved transforming code with ClojureScript
macros, so let's jump right in. You'll need to have `core.async` installed to run the
examples presented in this section.

==== Channels

Channels are like conveyor belts, we can put and take a single value at a time from them.
They can have multiple readers and writers and are the message-passing primitive of
`core.async`. Let's create a channel do some operations on it:

[source, clojure]
----
(require '[cljs.core.async :refer [chan put! take!]])

(enable-console-print!)

(def ch (chan))

(take! ch #(println "Got a value:" %))
;; => nil

;; there is a now a pending take operation, let's put something on the channel

(put! ch 42)
;; Got a value: 42
;; => 42
----

In the above example we created a channel (`ch`) using the `chan` constructor. After that
we performed a take operation on the channel, providing a callback that will be invoked
when the take operation succeeds. After using `put!` to put a value on the channel the
take operation completed and the `"Got a value: 42"` string was printed. Note that `put!`
returned the value that was just put to the channel.

The `put!` function also accepts a callback like `take!` does but we didn't provide any in
the last example. For puts the callback will be called whenever the value we provided has
been taken. Puts and takes can happen in any order, let's do a few puts followed by
takes to illustrate the point:

[source, clojure]
----
(require '[cljs.core.async :refer [chan put! take!]])

(def ch (chan))

(put! ch 42 #(println "Just put 42"))
;; => true
(put! ch 43 #(println "Just put 43"))
;; => true

(take! ch #(println "Got" %))
;; Got 42
;; Just put 42
;; => nil

(take! ch #(println "Got" %))
;; Got 43
;; Just put 43
;; => nil
----

You may be asking yourself why the `put!` operations return `true`. It signals that the
put operation could be performed, even though the value hasn't yet been taken. Channels
can be closed, which will cause the put operations to not succeed:

[source, clojure]
----
(require '[cljs.core.async :refer [chan put! close!]])

(def ch (chan))

(close! ch)
;; => nil

(put! ch 42)
;; => false
----

The above example was the simplest possible situation but what happens with pending
operations when a channel is closed? Let's do a few takes and close the channel and see
what happens:

[source, clojure]
----
(require '[cljs.core.async :refer [chan put! take! close!]])

(def ch (chan))

(take! ch #(println "Got value:" %))
;; => nil
(take! ch #(println "Got value:" %))
;; => nil

(close! ch)
;; Got value: nil
;; Got value: nil
;; => nil
----

We see that if the channel is closed all the `take!` operations receive a `nil` value.
`nil` in channels is a sentinel value that signals to takers that the channel has been
closed. Because of that, putting a `nil` value on a channel is not allowed:

[source, clojure]
----
(require '[cljs.core.async :refer [chan put!]])

(def ch (chan))

(put! ch 42)
;; Error: Assert failed: Can't put nil in on a channel
----

===== Buffers

We've seen that pending take and put operations are enqueued in a channel but, what
happens when there are many pending take or put operations? Let's find out by hammering a
channel with many puts and takes:

[source, clojure]
----
(require '[cljs.core.async :refer [chan put! take!]])

(def ch (chan))

(dotimes [n 1025]
  (put! ch n))
;; Error: Assert failed: No more than 1024 pending puts are allowed on a single channel.

(def ch (chan))

(dotimes [n 1025]
  (take! ch #(println "Got" %)))
;; Error: Assert failed: No more than 1024 pending takes are allowed on a single channel.
----

As the example above shows there's a limit of pending puts or takes on a channel, it's
currently 1024 but that is an implementation detail that may change. Note that there can't
be both pending puts and pending takes on a channel since puts will immediately succeed
if there are pending takes and viceversa.

Channels support buffering of put operations. If we create a channel with a buffer the put
operations will succeed immediately if there's room in the buffer and be enqueued
otherwise. Let's illustrate the point creating a channel with a buffer of one element. The
`chan` constructors accepts a number as its first argument which will cause it to have
a buffer with the given size:

[source, clojure]
----
(require '[cljs.core.async :refer [chan put! take!]])

(def ch (chan 1))

(put! ch 42 #(println "Put succeeded!"))
;; Put succeeded!
;; => true

(dotimes [n 1024]
  (put! ch n))
;; => nil

(put! ch 42)
;; Error: Assert failed: No more than 1024 pending puts are allowed on a single channel.
----

What happened in the example above? We created a channel with a buffer of size 1 and
performed a put operation on it that succeeded immediately because the value was buffered.
After that we did another 1024 puts to fill the pending put queue and, when trying to put
one value more the channel complained about not being able to enqueue more puts.

Now that we know about how channels work and what are buffers used for let's explore the
different buffers that `core.async` implements. Different buffers have different policies
and it's interesting to know all of them to know when to use what. Channels are unbuffered
by default.

====== Fixed

The fixed size buffer is the one that is created when we give the `chan` constructor a
number and it will have the size specified by the given number. It is the simplest
possible buffer: when full, puts will be enqueued.

The `chan` constructor accepts either a number or a buffer as its first argument. The two
channels created in the following example both use a fixed buffer of size 32:

[source, clojure]
----
(require '[cljs.core.async :refer [chan buffer]])

(def a-ch (chan 32))

(def another-ch (chan (buffer 32)))
----

====== Dropping

The fixed buffer allows put operations to be enqueued. However, as we saw before, puts
are still queued when the fixed buffer is full. If we wan't to discard the put operations
that happen when the buffer is full we can use a dropping buffer.

Dropping buffers have a fixed size and, when they are full puts will complete but their
value will be discarded. Let's illustrate the point with an example:

[source, clojure]
----
(require '[cljs.core.async :refer [chan dropping-buffer put! take!]])

(def ch (chan (dropping-buffer 2)))

(put! ch 40)
;; => true
(put! ch 41)
;; => true
(put! ch 42)
;; => true

(take! ch #(println "Got" %))
;; Got 40
;; => nil
(take! ch #(println "Got" %))
;; Got 41
;; => nil
(take! ch #(println "Got" %))
;; => nil
----

We performed three put operations and the three of them succeded but, since the dropping
buffer of the channel has size 2, only the first two values were delivered to the takers.
As you can observe the third take is enqueued since there is no value available, the third
put's value (42) was discarded.

====== Sliding

The sliding buffer has the opposite policy than the dropping buffer. When full puts will
complete and the oldest value will be discarded in favor of the new one. The sliding
buffer is useful when we are interested in processing the last puts only and we can afford
discarding old values.

[source, clojure]
----
(require '[cljs.core.async :refer [chan sliding-buffer put! take!]])

(def ch (chan (sliding-buffer 2)))

(put! ch 40)
;; => true
(put! ch 41)
;; => true
(put! ch 42)
;; => true

(take! ch #(println "Got" %))
;; Got 41
;; => nil
(take! ch #(println "Got" %))
;; Got 42
;; => nil
(take! ch #(println "Got" %))
;; => nil
----

We performed three put operations and the three of them succeded but, since the sliding
buffer of the channel has size 2, only the last two values were delivered to the takers.
As you can observe the third take is enqueued since there is no value available since the
first put's value was discarded.

===== Transducers

As mentioned in the section about transducers, putting values in a channel can be thought
as a transducible process. This means that we can create channels and hand them a
transducer, giving us the ability to transform the input values before being put in the
channel.

If we want to use a transducer with a channel we must supply a buffer since the reducing
function that will be modified by the transducer will be the buffer's add function.
A buffer's add function is a reducing function since it takes a buffer and an input and
returns a buffer with such input incorporated.

[source, clojure]
----
(require '[cljs.core.async :refer [chan put! take!]])

(def ch (chan 1 (map inc)))

(put! ch 41)
;; => true

(take! ch #(println "Got" %))
;; Got 42
;; => nil
----

You may be wondering what happens to a channel when the reducing function returns a
reduced value. It turns out that the notion of termination for channels is being closed,
so channels will be closed when a reduced value is encountered:

[source, clojure]
----
(require '[cljs.core.async :refer [chan put! take!]])

(def ch (chan 1 (take 2)))

(take! ch #(println "Got" %))
;; => nil
(take! ch #(println "Got" %))
;; => nil
(take! ch #(println "Got" %))
;; => nil

(put! ch 41)
;; => true
(put! ch 42)
;; Got 41
;; => true
(put! ch 43)
;; Got 42
;; Got nil
;; => false
----

We used the `take` stateful transducer to allow maximum 2 puts into the channel. We then
performed three take operations on the channel and we expect only two to receive a value.
As you can see in the above example the third take got the sentinel `nil` value which
indicates that the channel was closed. Also, the third put operation returned `false`
indicating that it didn't take place.

===== Handling exceptions

If adding a value to a buffer throws an exception `core.async` the operation will fail and
the exception will be logged to the console. However, channel constructors accept a third
argument: a function for handling exceptions.

When creating a channel with an exception handler it will be called with the exception
whenever an exception occurs. If the handler returns `nil` the operation will fail
silently and if it returns another value the add operation will be retried with such
value.

[source, clojure]
----
(require '[cljs.core.async :refer [chan put! take!]])

(enable-console-print!)

(defn exception-xform
  [rfn]
  (fn [acc input]
    (throw (js/Error. "I fail!"))))

(defn handle-exception
  [ex]
  (println "Exception message:" (.-message ex))
  42)

(def ch (chan 1 exception-xform handle-exception))

(put! ch 0)
;; Exception message: I fail!
;; => true

(take! ch #(println "Got:" %))
;; Got: 42
;; => nil
----

===== Offer and Poll

We've learned about the two basic operations on channels so far: `put!` and `take!`. They
either take or put a value and are enqueued if they can't be performed immediately. Both
functions are asynchronous because of the nature: they can succeed but be completed at a
later time.

`core.async` has two synchronous operations for putting or taking values: `offer!` and
`poll!`. These two operations will only succeed if they can be completed immediately. This
means that `offer!` can only succeed when there are pending takes and `poll!` when there
are pending puts.

[source, clojure]
----
(require '[cljs.core.async :refer [chan put! take! offer! poll!]])

;; TODO: wait for core.async release for documenting offer! and poll!
----

==== Processes

We learned all about channels but there is still a missing piece in the puzzle: processes.
Processes are pieces of logic that run independently and use channels for communication
and coordination. Puts and takes inside a process will stop the process until the
operation completes. Stopping a process doesn't block the only thread we have in the
environments where ClojureScript runs. Instead, it will be resumed at a later time when
the operation has been performed.

Processes are launched using the `go` macro and puts and takes use the `<!` and `>!`
placeholders. The `go` macro rewrites your code to use callbacks but inside `go`
everything looks like synchronous code, which makes understanding it easier:

[source, clojure]
----
(require '[cljs.core.async :refer [chan <! >!]])
(require-macros '[cljs.core.async.macros :refer [go]])

(enable-console-print!)

(def ch (chan))

(println "Starting block 1")
(go
  (println "Started block 1, gonna take from channel")
  (println "Got" (<! ch)))

(println "Starting block 2")
(go
  (println "Started block 2, gonna put on channel")
  (>! ch 42)
  (println "Just put 42"))

;; Starting block 1
;; Started block 1, gonna take from channel
;; Starting block 2
;; Started block 2, gonna put on channel
;; Just put 42
;; Got 42
----

In the above example we are launching a process with `go` that takes a value from `ch` and
prints it to the console. Since the value isn't immediately available it will park until
it can resume. After that we launch another process that puts a value on the channel.
Since there is a pending take the put operation succeeds and the value is delivered to
the first process, then both processes terminate.

TODO: example with timeout

[source, clojure]
----
(require '[cljs.core.async :refer [chan <! >! timeout]])
(require-macros '[cljs.core.async.macros :refer [go]])

(enable-console-print!)

(def ch (chan))
----

===== Choice

TODO: example using timeout for choice
TODO: canonical examples with alts (for example web search)

==== Combinators

- pipe, pipeline, pipeline-async, split, reduce, onto-chan, to-chan

==== Higher-level abstractions

===== Mixer

===== Mult

===== Pub-sub

==== A complete example

TODO: an example of a non-trivial task accomplished using processes and channels